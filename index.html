<!doctype html>
<html>
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <title>fgplvm by lawrennd</title>

    <link rel="stylesheet" href="stylesheets/styles.css">
    <link rel="stylesheet" href="stylesheets/github-light.css">
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
  </head>
  <body>
    <div class="wrapper">
      <header>
        <h1>fgplvm</h1>
        <p>Faster GP-LVM software in MATLAB.</p>

        <p class="view"><a href="https://github.com/lawrennd/fgplvm">View the Project on GitHub <small>lawrennd/fgplvm</small></a></p>


        <ul>
          <li><a href="https://github.com/lawrennd/fgplvm/zipball/master">Download <strong>ZIP File</strong></a></li>
          <li><a href="https://github.com/lawrennd/fgplvm/tarball/master">Download <strong>TAR Ball</strong></a></li>
          <li><a href="https://github.com/lawrennd/fgplvm">View On <strong>GitHub</strong></a></li>
        </ul>
      </header>
      <section>
        <h1>
<a id="faster-gp-lvm-software" class="anchor" href="#faster-gp-lvm-software" aria-hidden="true"><span class="octicon octicon-link"></span></a>Faster GP-LVM Software</h1>

<p>This page describes examples of how to use the fast Gaussian process latent variable model Software (FGPLVM). This toolbox allows for larger GP-LVM models through using the sparse approximations suggested in papers by authors including Titsias, Snelson, Ghahramani, Seeger, and Lawrence.</p>

<h2>
<a id="release-information" class="anchor" href="#release-information" aria-hidden="true"><span class="octicon octicon-link"></span></a>Release Information</h2>

<p><strong>Current release is 0.163</strong>.</p>

<p>As well as downloading the FGPLVM software you need to obtain the toolboxes specified below.</p>

<table>
<thead>
<tr>
<th><strong>Toolbox</strong></th>
<th><strong>Version</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="/netlab/downloadFiles/vrs3p3">NETLAB</a></td>
<td>3.3</td>
</tr>
<tr>
<td><a href="/prior/downloadFiles/vrs0p22">PRIOR</a></td>
<td>0.22</td>
</tr>
<tr>
<td><a href="/optimi/downloadFiles/vrs0p132">OPTIMI</a></td>
<td>0.132</td>
</tr>
<tr>
<td><a href="/datasets/downloadFiles/vrs0p1371">DATASETS</a></td>
<td>0.1371</td>
</tr>
<tr>
<td><a href="/kern/downloadFiles/vrs0p225">KERN</a></td>
<td>0.225</td>
</tr>
<tr>
<td><a href="/ndlutil/downloadFiles/vrs0p162">NDLUTIL</a></td>
<td>0.162</td>
</tr>
<tr>
<td><a href="/noise/downloadFiles/vrs0p141">NOISE</a></td>
<td>0.141</td>
</tr>
<tr>
<td><a href="/mocap/downloadFiles/vrs0p136">MOCAP</a></td>
<td>0.136</td>
</tr>
</tbody>
</table>

<p>Changes for compatibility with new SGPLVM toolbox by Carl Henrik Ek.</p>

<h4>
<a id="version-0162" class="anchor" href="#version-0162" aria-hidden="true"><span class="octicon octicon-link"></span></a>Version 0.162</h4>

<p>Added new files fgplvmWriteResults fgplvmLoadResults for saving smaller model files.</p>

<h4>
<a id="version-0161" class="anchor" href="#version-0161" aria-hidden="true"><span class="octicon octicon-link"></span></a>Version 0.161</h4>

<p>Updates for running a GPLVM when the inner produce matrix is used (i.e. dimensionality much greater than data points). Minor changes to fix reading of GPLVM files from latest C++ code.</p>

<h4>
<a id="version-016" class="anchor" href="#version-016" aria-hidden="true"><span class="octicon octicon-link"></span></a>Version 0.16</h4>

<p>Incorporate varational approximation from Michalis in the code.</p>

<h4>
<a id="version-0153" class="anchor" href="#version-0153" aria-hidden="true"><span class="octicon octicon-link"></span></a>Version 0.153</h4>

<p>Changes to allow compatibility with SGPLVM and NCCA toolboxes.</p>

<h4>
<a id="version-0152" class="anchor" href="#version-0152" aria-hidden="true"><span class="octicon octicon-link"></span></a>Version 0.152</h4>

<p>Bug fix from fgplvmReadFromFID where the values of model.m weren't being computed correctly.</p>

<h4>
<a id="version-0151" class="anchor" href="#version-0151" aria-hidden="true"><span class="octicon octicon-link"></span></a>Version 0.151</h4>

<p>In this version results for the CMU Mocap data set from <a href="http://www.cs.man.ac.uk/neill-bin/publications/bibpage.cgi?keyName=Taylor:motion06&amp;printAbstract=1">Taylor et al.</a> of subject 35 running and walking are included, as well as some minor changes to allow hierarchical GP-LVMs to be used.</p>

<h4>
<a id="version-015" class="anchor" href="#version-015" aria-hidden="true"><span class="octicon octicon-link"></span></a>Version 0.15</h4>

<p>This version splits the Gaussian process portion into a new GP toolbox, the corresponding version is 0.1. Fixed bug in gpDynamicsExpandParam, gpDynamicsExractParam and gpDynamicsLogLikeGradient where 'fixInducing' option was not being dealt with.</p>

<p>Fixed bug in fgplvmCreate.m where the back constraints were set up, but the latent positions were not being set according to the back constraints in the returned model.</p>

<h4>
<a id="version-0141" class="anchor" href="#version-0141" aria-hidden="true"><span class="octicon octicon-link"></span></a>Version 0.141</h4>

<p>Changed GP-LVM default optimiser to scg rather than conjgrad. Added fgplvmOptimiseSequence and dependent files. This is for optimising a test sequence in the latent space, for the case where there are dynamics on the model.</p>

<h4>
<a id="version-014" class="anchor" href="#version-014" aria-hidden="true"><span class="octicon octicon-link"></span></a>Version 0.14</h4>

<p>Carl Ek implemented multiple sequences in the gpDynamics model used for dynamics in the GPLVM, this was refined and integrated by Neil.</p>

<p>Fixed two bugs in gpPosteriorGradMeanVar which appeared if fitc was used or the scales on the outputs were non-zero. This in turn affected fgplvmOptimisePoint.</p>

<p>Default under back constraints switched to not optimise towards a PCA initialisation.</p>

<p>Fixed bug in fgplvmReadFromFID where the old form of fgplvmCreate was being called.</p>

<h4>
<a id="version-0132" class="anchor" href="#version-0132" aria-hidden="true"><span class="octicon octicon-link"></span></a>Version 0.132</h4>

<p>Release 0.132 includes two speed improvements on the pitc approximation. Thanks to <a href="http://www.gatsby.ucl.ac.uk/%7Esnelson/">Ed Snelson</a> for pointing out that it was unusually slow! New versions of the NDLUTIL and KERN toolbox are also required.</p>

<p>Release 0.131 adds the ability to handle missing data and a new reversible dynamics model.</p>

<p>Release 0.13 is a (hopefully) fairly stable base release for which several results in forthcoming papers will be created. Additional features are better decompartmentalisation of dynamics models, regularisation of inducing variable's inputs and introduction of fgplvmOptions and gpOptions for setting default options for the models.</p>

<p>Release 0.11 is the first release that contains the fully independent training conditional approximation (Snelson and Ghahramani, Quinonero Candela and Rasmussen).</p>

<p>Release 0.1 is a pre-release to make some of the model functionality available. The some of the different approximations (such as fully independent training conditional and partially independent training conditional) are not yet implemented and the dynamics currently has no sparse approximations associated.</p>

<p>This toolbox also implements back constraints (joint work with Joaquin Quinonero Candela). The mappings that can be used as back constraints are those described in <a href="/mltools/downloadFiles/">the MLTOOLS toolbox</a>.</p>

<p>Alternative GP-LVM implementations from this site:</p>

<p>The GP-LVM C++ software is available from <a href="/gplvmcpp/">here</a>.</p>

<p>The original MATLAB version of the toolbox is available here <a href="/gplvm/">here</a>.</p>

<h2>
<a id="examples" class="anchor" href="#examples" aria-hidden="true"><span class="octicon octicon-link"></span></a>Examples</h2>

<h3>
<a id="gp-lvm" class="anchor" href="#gp-lvm" aria-hidden="true"><span class="octicon octicon-link"></span></a>GP-LVM</h3>

<p>The three approximations outlined above can be used to speed up learning in the GP-LVM. They have the advantage over the IVM approach taken in the <a href="/gplvm/">original GP-LVM toolbox</a> that the algorithm is fully convergent and the final mapping from latent space to data space takes into account all of the data (not just the points in the active set).</p>

<p>As well as the new sparse approximation the new toolbox allows the GP-LVM to be run with dynamics as suggested by <a href="http://www.cs.man.ac.uk/neill-bin/publications/bibpage.cgi?keyName=Wang:gpdm05&amp;printAbstract=1">Wang <em>et al.</em></a>.</p>

<p>Finally, the new toolbox allows the incorporation of 'back constraints' in learning. Back constraints force the latent points to be a smooth function of the data points. This means that points that are close in data space are constrained to be close in latent space. For the standard GP-LVM points close in latent space are constrained to be close in data space, but the converse is not true.</p>

<p>Various combinations of back constraints and different approximations are used in the exmaples below.</p>

<h3>
<a id="oil-data" class="anchor" href="#oil-data" aria-hidden="true"><span class="octicon octicon-link"></span></a>Oil Data</h3>

<p>The 'oil data' is commonly used as a bench mark for visualisation algorithms. For more details on the data see <a href="/3PhaseData.html">this page</a>.</p>

<p>The <a href="/gplvmcpp">C++ implementation of the GP-LVM</a> has details on training the full GP-LVM with this data set. Here we will consider the three different approximations outlined above.</p>

<h4>
<a id="fitc-approximation" class="anchor" href="#fitc-approximation" aria-hidden="true"><span class="octicon octicon-link"></span></a>FITC Approximation</h4>

<p>In all the examples we give there will be 100 points in the active set. We first considered the FITC approximation. The script <code>demOilFgplvm1.m</code> runs the FITC approximation giving the result on the left of the figure shown below.</p>

<p><img src="demOilFgplvm1.png" alt=""><img src="demOilFgplvm2.png" alt=""></p>

<p><em>Left</em>: GP-LVM on the oil data using the FITC approximation without back constraints. The phases of flow are shown as green circles, red crosses and blue plusses. One hundred inducing variables are used. <em>Right</em>: Similar but for a back-constrained GP-LVM, the back constraint is provided by a multi-layer perceptron with 15 hidden nodes.
Back constraints can be added to each of these approximations. In the example on the right we used a back constraint given by a multi-layer perceptron with 15 hidden nodes. This example can be recreated with <code>demOilFgplvm2.m</code>.</p>

<h4>
<a id="dtc-approximation" class="anchor" href="#dtc-approximation" aria-hidden="true"><span class="octicon octicon-link"></span></a>DTC Approximation</h4>

<p>The other approximations can also be used, in the figures below we give results from the DTC approximation. The can be recreated using <code>demOil3.m</code> and <code>demOil4.m</code>.</p>

<p><img src="demOilFgplvm3.png" alt=""><img src="demOilFgplvm4.png" alt=""></p>

<p><em>Left</em>: GP-LVM on the oil data using the DTC approximation without back constraints. The phases of flow are shown as green circles, red crosses and blue plusses. One hundred inducing variables are used. <em>Right</em>: Similar but for a back-constrained GP-LVM, the back constraint is provided by a multi-layer perceptron with 15 hidden nodes.</p>

<h4>
<a id="pitc-approximation" class="anchor" href="#pitc-approximation" aria-hidden="true"><span class="octicon octicon-link"></span></a>PITC Approximation</h4>

<p>We also show results using the PITC approximation, these results can be recreated using the scripts <code>demOilFgplvm5.m</code> and <code>demOilFgplvm6.m</code>.</p>

<p><img src="demOilFgplvm5.png" alt=""><img src="demOilFgplvm6.png" alt=""></p>

<p><em>Left</em>: GP-LVM on the oil data using the PITC approximation without back constraints. The phases of flow are shown as green circles, red crosses and blue plusses. One hundred inducing variables are used. <em>Right</em>: Similar but for a back-constrained GP-LVM, the back constraint is provided by a multi-layer perceptron with 15 hidden nodes.</p>

<h4>
<a id="variational-dtc-approximation" class="anchor" href="#variational-dtc-approximation" aria-hidden="true"><span class="octicon octicon-link"></span></a>Variational DTC Approximation</h4>

<p>Finally we also show results using the variational DTC approximation of Titsias, these results can be recreated using the scripts <code>demOilFgplvm7.m</code> and <code>demOilFgplvm8.m</code>.</p>

<p><img src="demOilFgplvm7.png" alt=""><img src="demOilFgplvm8.png" alt=""></p>

<p><em>Left</em>: GP-LVM on the oil data using the variational DTC approximation without back constraints. The phases of flow are shown as green circles, red crosses and blue plusses. One hundred inducing variables are used. <em>Right</em>: Similar but for a back-constrained GP-LVM, the back constraint is provided by a multi-layer perceptron with 15 hidden nodes.</p>

<h3>
<a id="back-constraints-and-dynamics" class="anchor" href="#back-constraints-and-dynamics" aria-hidden="true"><span class="octicon octicon-link"></span></a>Back Constraints and Dynamics</h3>

<p>First we will demonstrate the dynamics functionality of the toolbox. We raw x-y-z values from a motion capture data set, the <code>Figure Run 1</code> example available <a href="http://accad.osu.edu/research/mocap/mocap_data.htm">from Ohio State University</a>. To run without dynamics use the script:</p>

<div class="highlight highlight-matlab"><pre><span class="pl-k">&gt;&gt; </span>demStickFgplvm1</pre></div>

<p>The results are given on the left of the figure below.</p>

<p><img src="demStickFgplvm1.png" alt=""></p>

<p>GP-LVM on the motion capture data without dynamics in the latent space.
Notice that the sequence (which is a few strides of a man running) is split into several sub-sequences. These sub-sequences are aligned to the strides of the man. By introducing a dynamics prior, we can force the sequence to link up. Samples from the dynamics prior used are shown in the plot below.</p>

<p><img src="dynamicsSamp1.png" alt=""><img src="dynamicsSamp2.png" alt="">
 <img src="dynamicsSamp3.png" alt=""><img src="dynamicsSamp4.png" alt=""></p>

<p>Samples from the dynamics prior which is placed over the latent space. This prior has <em>Left</em>: GP-LVM on the motion capture data without dynamics in the latent space. <em>Right</em>: GP-LVM with dynamics. Samples from the dynamics prior used are given in the figure above.
This prior is used in the model to obtain the results below,</p>

<div class="highlight highlight-matlab"><pre><span class="pl-k">&gt;&gt; </span>demStickFgplvm2</pre></div>

<p><img src="demStickFgplvm2.png" alt=""></p>

<p>GP-LVM with dynamics. Samples from the dynamics prior used are given in the figure above.
Note now the circular form of the latent space. Back constraints can also be used to achieve a similar effect,</p>

<div class="highlight highlight-matlab"><pre><span class="pl-k">&gt;&gt; </span>demStickFgplvm3</pre></div>

<p><img src="demStickFgplvm3.png" alt=""></p>

<p>GP-LVM with back constraints. A RBF kernel mapping was used to form the back constraints with the inverse width set to 1e-4 (<em>i.e.</em>length scale set to 100).</p>

<h3>
<a id="loop-closure-in-robotics" class="anchor" href="#loop-closure-in-robotics" aria-hidden="true"><span class="octicon octicon-link"></span></a>Loop Closure in Robotics</h3>

<p>In on-going work with Dieter Fox and Brian Ferris at the University of Washington we are interested in loop closure for robotic navigation, included as an example is a data set of a robot completing a loop while reading wireless access point signal strengths. To produce a neat track and close the loop it turns out it is necessary to use dynamics and back constraints as seen in the images below. These results can be recreated with
<code>demRobotWireless1.m</code> through <code>demRobotWireless4.m</code>.</p>

<p><img src="demRobotWireless1.png" alt=""><img src="demRobotWireless2.png" alt="">
<img src="demRobotWireless3.png" alt=""><img src="demRobotWireless4.png" alt=""></p>

<p>Use of back constraints and dynamics to obtain loop closure in a robot navigation example. <em>Top Left</em>: GP-LVM without back constraints or dynamics, <em>Top right</em>: GP-LVM with back constraints, no dynamics, <em>Bottom Left</em>: GP-LVM with dynamics, no back constraints, <em>Bottom right</em>: GP-LVM with back constraints and dynamics.</p>

<h3>
<a id="vocal-joystick-and-vowel-data" class="anchor" href="#vocal-joystick-and-vowel-data" aria-hidden="true"><span class="octicon octicon-link"></span></a>Vocal Joystick and Vowel Data</h3>

<p>Another ongoing piece of work with Jeff Bilmes and Jon Malkin involves embedding vowel sounds in a two dimensional space as part of <a href="http://ssli.ee.washington.edu/vj">vocal joystick</a> system. Jon has provided a simple data set of 2,700 examples of different vowels. These are embedded in a two dimensional latent space with and without back constraints.</p>

<p><img src="demVowels2.png" alt=""><img src="demVowels3.png" alt=""></p>

<p><em>Left</em>: embedding of the vowel data without back constraints, <em>Right</em>: embedding of the vowel data with back constraints. <em>/a/</em> - red cross, <em>/ae/</em> - green circle, <em>/ao/</em> - blue plus, <em>/e/</em> - cyan asterix, <em>/i/</em> - magenta square, <em>/ibar/</em> - yellow diamond, <em>/o/</em> - red down triangle, <em>/schwa/</em> - green up triangle, <em>/u/</em> - blue left triangle.</p>

<h3>
<a id="larger-human-motion-data-sets" class="anchor" href="#larger-human-motion-data-sets" aria-hidden="true"><span class="octicon octicon-link"></span></a>Larger Human Motion Data Sets</h3>

<p>For <a href="http://ml.sheffield.ac.uk/%7Eneil/cgi-bin/publications/bibpage.cgi?keyName=Lawrence:larger07&amp;printAbstract=1">an AISTATS paper</a> we recreated an experiment from <a href="/neill-bin/publications/bibpage.cgi?keyName=Taylor:motion06&amp;printAbstract=1">Taylor <em>et al.</em>'s NIPS paper</a>. They created a data set from a motion capture data in the <a href="http://mocap.cs.cmu.edu">CMU data base</a> of running and walking. The data set can now be recreated using the <a href="/datasets/">DATASETS toolbox</a>. We repeated missing data experiments by Taylor et al.. The model learning for these experiments can be recreated with:</p>

<div class="highlight highlight-matlab"><pre><span class="pl-k">&gt;&gt; </span>demCmu35gplvm1</pre></div>

<p>for the four dimensional latent space, <code>demCmu35gplvm2</code> for the three dimensional latent space and <code>demCmu35gplvm3</code> for the five dimensional latent space. The test data reconstruction can then be performed for all models with <code>demCmu35gplvmReconstruct</code>. Taylor <em>et al.</em>'s nearest neighbour results can be recreated using <code>demCmu35TaylorNearestNeighbour</code>.</p>

<p>Data was pre-processed by mapping angles to be between -180 and 180 and scaling the data such that the variance of each dimension was one.</p>

<p>The quality of the trained model was evaluated using a missing data problem with a test sequence of data. The model was required to fill in either upper body angles or right leg angles. Results for the GP-LVM and nearest neighbour in both scaled space and original angle space are given in the table below.</p>

<table>







<tbody>
<tr>
<td align="left"></td>
<td align="left">Leg Cumulative Scaled</td>
<td align="left">Leg RMS Angles</td>
<td align="left">Body Cumulative Scaled</td>
<td align="left">Body RMS Angles</td>
</tr>
<tr>
<td align="left">GP-LVM (<em>q</em>=3)</td>
<td align="left">11.4</td>
<td align="left">3.40</td>
<td align="left"><strong>16.9</strong></td>
<td align="left"><strong>2.49</strong></td>
</tr>
<tr>
<td align="left">GP-LVM (<em>q</em>=4)</td>
<td align="left"><strong>9.7</strong></td>
<td align="left"><strong>3.38</strong></td>
<td align="left">20.7</td>
<td align="left">2.72</td>
</tr>
<tr>
<td align="left">GP-LVM (<em>q</em>=5)</td>
<td align="left"><strong>13.4</strong></td>
<td align="left">4.25</td>
<td align="left">23.4</td>
<td align="left">2.78</td>
</tr>
<tr>
<td align="left">Scaled NN</td>
<td align="left"><strong>13.5</strong></td>
<td align="left">4.44</td>
<td align="left">20.8</td>
<td align="left">2.62</td>
</tr>
<tr>
<td align="left">Nearest Neighbour</td>
<td align="left"><strong>14.0</strong></td>
<td align="left">4.11</td>
<td align="left">30.9</td>
<td align="left">3.20</td>
</tr>
</tbody>
</table>

<p>The cumulative scaled error is a recreation of the error reported in Taylor <em>et al.</em> which was the average (across angles) cumulative sum (across time) of the squared errors in the down-scaled (<em>i.e.</em> variance one) space of angles. We also present the root mean squared angle error for each joint which we find to be a little easier to interpret.</p>

<p>Taylor <em>et al.</em> used a slightly different representation of the data set which included the absolute <em>x</em> and <em>z</em> position of the root node and rotation around the <em>y</em>-axis. For this data set, this information does help, principally because the subject seems to start in roughly the same position at the beginning of each sequence. However, in general absolute position will not help, so we discarded it in favour of a representation of these values in terms of differences between frames. Finally Taylor <em>et al.</em> concatenated two frames to form each data point for the model. We chose not to do this as we wanted to test the ability of the Gaussian process dynamics to fully recreate the data set. There results are given in their paper and summarised below.</p>

<table>





<tbody>
<tr>
<td align="left"></td>
<td align="left">Leg Cumulative Scaled</td>
<td align="left">Body Cumulative Scaled</td>
</tr>
<tr>
<td align="left">Binary Latent Variable Model</td>
<td align="left"><strong>11.7</strong></td>
<td align="left"><strong>8.8</strong></td>
</tr>
<tr>
<td align="left">Scaled NN</td>
<td align="left">22.2</td>
<td align="left">20.5</td>
</tr>
</tbody>
</table>

<p>Finally we show a plot of reconstructions of two of the angles in the data.</p>

<p><img src="demCmu35gplvmLegReconstruct1_8.png" alt=""><img src="demCmu35gplvmLegReconstruct1_9.png" alt=""></p>

<p>Prediction for first two angles of the right hip joint (see plots in <a href="/neill-bin/publications/bibpage.cgi?keyName=Taylor:motion06&amp;printAbstract=1">Taylor <em>et al.</em></a> for comparison). Dotted line is nearest neighour in scaled space, dashed line is GP-LVM with 4-D latent space.</p>

<p>Page updated on Wed May 19 10:04:54 2010</p>
      </section>
      <footer>
        <p>This project is maintained by <a href="https://github.com/lawrennd">lawrennd</a></p>
        <p><small>Hosted on GitHub Pages &mdash; Theme by <a href="https://github.com/orderedlist">orderedlist</a></small></p>
      </footer>
    </div>
    <script src="javascripts/scale.fix.js"></script>
              <script type="text/javascript">
            var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
            document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
          </script>
          <script type="text/javascript">
            try {
              var pageTracker = _gat._getTracker("UA-62968536-1");
            pageTracker._trackPageview();
            } catch(err) {}
          </script>

  </body>
</html>
